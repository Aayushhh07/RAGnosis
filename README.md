# ğŸš€ RAGnosis â€“ Retrieval-Augmented Knowledge Assistant

<p align="center">
  <b>Hallucination-Free Document Question Answering</b><br>
  <i>Semantic search, grounded answers, and source attribution using open-source LLMs.</i>
</p>

<p align="center">
  <a href="#-features">âœ¨ Features</a> |
  <a href="#-quickstart">âš¡ Quickstart</a> |
  <a href="#-architecture">ğŸ›  Architecture</a> |
  <a href="#-tech-stack">ğŸ§© Tech Stack</a> |
  <a href="#-use-cases">ğŸ¯ Use Cases</a>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/LLM-Mistral%20%7C%20Phi%20%7C%20Gemma-blue" alt="LLM"/>
  <img src="https://img.shields.io/badge/VectorDB-FAISS-brightgreen" alt="FAISS"/>
  <img src="https://img.shields.io/badge/Embeddings-SentenceTransformers-orange" alt="Embeddings"/>
  <img src="https://img.shields.io/badge/UI-Streamlit-red" alt="Streamlit"/>
</p>

---

## ğŸ“‘ Table of Contents
- [About](#-about)
- [Features](#-features)
- [Quickstart](#-quickstart)
- [Architecture](#-architecture)
- [Tech Stack](#-tech-stack)
- [Use Cases](#-use-cases)
- [Project Structure](#-project-structure)
- [Author](#-author)
- [License](#-license)

---

## ğŸ§ About

**RAGnosis** is an end-to-end **Retrieval-Augmented Generation (RAG)** platform designed to answer user queries **strictly from a given set of documents**.

Unlike traditional LLM chatbots that rely on pre-trained knowledge and may hallucinate, RAGnosis:
- Retrieves **relevant document context**
- Injects it into the LLM prompt
- Generates **grounded, verifiable answers with source references**

The system is built entirely using **open-source models and frameworks**, making it suitable for **academic, enterprise, and on-premise use cases**.

---

## âœ¨ Features

### ğŸ“„ Document Intelligence
- Supports **PDF, TXT, and Markdown** documents
- Automatic document ingestion & preprocessing
- Intelligent text chunking with overlap

### ğŸ”¢ Semantic Search
- Dense vector embeddings using **Sentence Transformers**
- High-performance similarity search using **FAISS**
- Query-to-document semantic matching (not keyword-based)

### ğŸ§  Context-Aware Answering
- Retrieval-augmented prompt construction
- Deterministic answer generation (low temperature)
- Explicit *â€œanswer only from contextâ€* enforcement

### ğŸ›¡ Safety & Reliability
- Hallucination prevention guardrails
- Confidence thresholding
- Mandatory source attribution
- Graceful fallback when context is insufficient

### ğŸ–¥ User Interface
- Simple, clean **Streamlit UI**
- Real-time question answering
- Transparent source visibility

---

## âš¡ Quickstart

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/Aayushhh07/RAGnosis.git
cd RAGnosis
```
### 2ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate 
```
### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```
### 4ï¸âƒ£ Add Documents
```bash
documents/
```
### 5ï¸âƒ£ Run the Application
```bash
streamlit run app.py
```

## ğŸ›  Architecture

```mermaid
flowchart TD
    %% USER INTERACTION
    U[ğŸ§‘ User Query] --> QE[ğŸ”¢ Query Embedding]

    %% VECTOR SEARCH
    QE --> VS[(ğŸ—‚ FAISS Vector Store)]
    VS --> RC[ğŸ“„ Retrieved Chunks]

    %% PROMPTING
    RC --> PA[ğŸ§  Prompt Augmentation]

    %% LLM
    PA --> LLM[ğŸ¤– Open-Source LLM]
    LLM --> GR[ğŸ›¡ Guardrails & Filtering]

    %% OUTPUT
    GR --> A[âœ… Final Answer]
    A --> S[ğŸ“š Source References]
```
## ğŸ§© Tech Stack

### **Core**
- **Python** â€“ Primary programming language
- **LangChain** â€“ RAG orchestration and chaining
- **Streamlit** â€“ Interactive web UI

### **Embeddings & Vector Search**
- **Sentence Transformers** â€“ Semantic text embeddings
- **FAISS** â€“ High-performance vector similarity search

### **LLM Inference**
- **Mistral / Phi / Gemma** â€“ Open-source large language models
- **Ollama** â€“ Local LLM serving and inference

### **Document Processing**
- **PyPDF** â€“ PDF parsing
- **Recursive Text Splitter** â€“ Efficient document chunking

### **Safety & Guardrails**
- Custom prompt constraints
- Context-only answer enforcement
- Confidence thresholding & fallback responses

---

## ğŸ¯ Use Cases

- **Academic Research** â€“ Question answering over research papers and notes  
- **Enterprise Knowledge Base** â€“ Internal document assistants for teams  
- **Education** â€“ Course material and syllabus-based Q&A  
- **Legal & Compliance** â€“ Source-verifiable and grounded responses  
- **On-Prem AI Systems** â€“ Fully offline, open-source RAG deployment  

---

## ğŸ“‚ Project Structure

```text
RAG/
â”œâ”€â”€ app.py                 # Streamlit UI
â”œâ”€â”€ rag_pipeline.py        # Core RAG pipeline
â”œâ”€â”€ document_processor.py  # Document ingestion and chunking
â”œâ”€â”€ embeddings.py          # Embedding generation
â”œâ”€â”€ vector_store.py        # FAISS vector database
â”œâ”€â”€ guardrails.py          # Safety controls and filtering
â”œâ”€â”€ documents/             # Input documents
â”œâ”€â”€ vector_store/          # Saved FAISS index
â””â”€â”€ requirements.txt       # Project dependencies
```
## ğŸ‘¨â€ğŸ’» Author

**Aayush Vishwakarma**  
- ğŸ’¼ UsefulBI Corporation  
- ğŸ“ India  
- ğŸ”— GitHub: https://github.com/Aayushhh07  
- ğŸ”— LinkedIn: https://www.linkedin.com/in/aayush-vishwakarma-68a8a92a1  
- ğŸ“¬ Email: aayushvishwakarma93@gmail.com  

---

## ğŸ“œ License

This project is licensed under the **MIT License**.  
You are free to use, modify, and distribute this project for academic, educational, and research purposes.


